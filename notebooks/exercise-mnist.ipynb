{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-19T12:52:10.672374Z","iopub.status.busy":"2023-09-19T12:52:10.671397Z","iopub.status.idle":"2023-09-19T12:52:10.736115Z","shell.execute_reply":"2023-09-19T12:52:10.734667Z","shell.execute_reply.started":"2023-09-19T12:52:10.672318Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:13.686496Z","iopub.status.busy":"2023-09-19T12:52:13.685983Z","iopub.status.idle":"2023-09-19T12:52:21.246475Z","shell.execute_reply":"2023-09-19T12:52:21.244867Z","shell.execute_reply.started":"2023-09-19T12:52:13.686449Z"},"trusted":true},"outputs":[],"source":["from fastai.vision.all import *\n","import torch\n","from torchvision import datasets, transforms\n","import torch.nn.functional as Fnn\n","import gzip\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## Learning how to build a CNN for MNIST dataset with Fastai and PyTorch \n","\n","Here's what I've learned while building a model that can recognize the value of handwritten digits from 0 - 9 using the MNIST dataset. This was an exercise I assigned to myself while learning the basics of computer vision and the associated engineering concepts.\n","\n","Below, you'll find some of my notes on the subject. I've learned alot about the subject recently, and some parts of my notes are extracts of a chat with an LLM.\n","\n","First, I'll summarize some peculiarities of the code and the challenges required to understand the problem. Then, we'll delve deeper into the code.\n","\n","I've used the Fastai API for some parts and pure PyTorch for others. "]},{"cell_type":"markdown","metadata":{},"source":["## Understanding how to create a multi-class classification model\n","During a Fastai lesson we've created an image classifer with the MNIST dataset. The base exercise was to classify handwritten digits `3` and `7` . An easy enough problem to understand the basis of computer vision.\n","\n","The problem type consisted of a binary classification(if it's not a `3` then it's a `7`).\n","We've resolved it by creating a simple linear Neural net that had a loss function that looked like this:\n","\n","````\n","\n","def mnist_loss(predictions, targets):\n","    preds = predictions.sigmoid() \n","    return torch.where(targets==1, 1-preds, preds).mean()\n","    \n","# use sigmoid on prediction logits so that preds will be normalized between 0.0 - 1.0  \n","\n","````\n","\n","Here we're applying a sigmoid function to the predictions and then comparing them to the targets. \n","As mentionned before, this approach is typically used for binary classification problems.\n","\n","The function is calculating the `mean loss` for a binary classification problem, where the loss is `1-preds` when the `target` is `1` (indicating that we want the prediction to be closer to 1), and `preds` when the `target` is `0` (indicating that we want the prediction to be closer to 0). This is a form of binary cross-entropy loss, but without the log function applied, and is suitable for binary classification problems where the labels are either 0 or 1.\n","\n","However, the new model I have created is a multi-class classification model (whole MNIST dataset, which has 10 classes wich are the digits (0 to 9)). \n","Therefore, I found out that when calculating the `loss` I should be using a `softmax` function instead of a `sigmoid` function. \n","For the batch accuracy calculation I should be comparing the `argmax` of my predictions to the targets instead of a function that uses a `sigmoid` function and a threshold of `0.5` to make predictions, which the latter is appropriate for binary classification.\n","\n","The `softmax` function is specifically designed to handle multiple classes. It outputs a vector that represents the probability distributions of a list of potential outcomes. It's a way of normalizing the output of a network to a probability distribution over predicted output classes.\n","On the other hand, the `sigmoid` function is used for binary classification problems. It squashes its input into a range between 0 and 1, which can be used to represent a probability. However, it treats each class independently and doesn't have a notion of a probability distribution over multiple classes. \n","\n","You'll notice `softmax` isn't visible in my loss function because the `F.cross_entropy` function in PyTorch applies the softmax function internally\n","when using `F.cross_entropy`, the predictions tensor should have the `shape` `(batch_size, num_classes`) and the targets tensor should have the `shape` `(batch_size,)`. The values in targets should be the class indices, not one-hot encoded vectors.\n","\n","----\n","\n","## About the architecture of the neural net\n","\n","The model created is a convolutional neural network (CNN) and it use `nn.Conv2d` , a 2D convolutional layer in PyTorch. It's an appropriate choice in several scenarios, particularly when dealing with image data or any kind of grid-like 2D data. \n","\n","You'll observe that the model has 3 layers and 32 hidden layers, after the convolutional layers, there's an AdaptiveAvgPool2d layer which applies average pooling to convert the feature maps to a size of 1x1, a Flatten layer to flatten the tensor into a vector, and finally a Linear layer to map the features to the 10 output classes.\n","\n","Let's break down the architecture of one layer in your CNN which consists of `Conv2d` + `ReLU` + `Dropout`.\n","\n","**Conv2d**\n","\n","The first part of the layer is 2D convolutional layer, it takes an input with 1 channel (e.g., a grayscale image), and applies 32 filters (or kernels) of size 5x5. The stride of 2 means that the filters move 2 pixels at a time, reducing the size of the output feature maps compared to the input. The padding of 1 adds extra pixels around the input feature map to control the spatial output size.\n","\n","**ReLU**\n","\n","`nn.ReLU()` This is the activation function. ReLU stands for Rectified Linear Unit. It introduces non-linearity into the model, allowing the network to learn more complex patterns. The function returns 0 if it receives any negative input, but for any positive value x, it returns that value back. \n","\n","**Dropout**\n","\n","Dropout is a regularization technique used in neural networks to prevent overfitting. \n","During training, dropout randomly sets a fraction of the input units to 0 at each update, which helps to prevent overfitting. The fraction of zeroed units is determined by a hyperparameter, usually denoted as p, which is the dropout rate. For example, if p is set to 0.5, approximately half of the input units will be dropped out, or set to zero.\n","\n","\n","Dropout is effective because it forces the network to learn redundant representations, and ensures that the output does not rely too heavily on any single neuron. This makes the network more robust and improves generalization.\n","\n","Remember, dropout is only used during training, not during testing or evaluation of the model.\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n","## Let's start \n","Pytorch as a built-in function to download MNIST datasets. Here's the link of all the others one available from the vision package https://pytorch.org/vision/stable/datasets.html\n","\n","Good to know: I have kept, as commented code, some usefull parts when working on different enviromnent."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T14:50:56.611108Z","iopub.status.busy":"2023-09-18T14:50:56.609546Z","iopub.status.idle":"2023-09-18T14:50:56.616431Z","shell.execute_reply":"2023-09-18T14:50:56.615256Z","shell.execute_reply.started":"2023-09-18T14:50:56.611055Z"},"trusted":true},"outputs":[],"source":["# Download MNIST dataset \n","# When not on Kaggle use below\n","# mnist = datasets.MNIST('./data', download=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:21.927334Z","iopub.status.busy":"2023-09-19T12:52:21.926479Z","iopub.status.idle":"2023-09-19T12:52:21.933967Z","shell.execute_reply":"2023-09-19T12:52:21.932961Z","shell.execute_reply.started":"2023-09-19T12:52:21.927289Z"},"trusted":true},"outputs":[],"source":["ROOT_DIR = os.path.dirname(os.path.abspath('')) \n","\n","#VSCODE/IDE \n","#DATA_DIR = os.getcwd() + ROOT_DIR + 'mnist-basics/data/MNIST/raw/'\n","#BROWSER\n","#DATA_DIR = ROOT_DIR + '/mnist-basics/data/MNIST/raw/'\n","\n","#Kaggle \n","DATA_DIR = '/kaggle/input/mnist-pytorch/'\n","print(DATA_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:24.080546Z","iopub.status.busy":"2023-09-19T12:52:24.080068Z","iopub.status.idle":"2023-09-19T12:52:24.091944Z","shell.execute_reply":"2023-09-19T12:52:24.090651Z","shell.execute_reply.started":"2023-09-19T12:52:24.080510Z"},"trusted":true},"outputs":[],"source":["# The kaggle dataset I use have already the ubyte file ungzipped, \n","# but I kept as a reference the function. The code for kaggle current env. use the other one below.\n","\n","# this function is useful when using the dataset from PyTorch as gzip\n","def load_mnist_as_gzip(path, kind='train'):\n","    \"\"\"Load MNIST data from `path`\"\"\"\n","    labels_path = os.path.join(path,'%s-labels-idx1-ubyte.gz'\n","                               % kind)\n","    images_path = os.path.join(path,'%s-images-idx3-ubyte.gz'\n","                               % kind)\n","    print(labels_path)\n","    print(images_path)\n","    with gzip.open(labels_path, 'rb') as lbpath:\n","        labels = torch.from_numpy(np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8).copy())\n","    print(f'Number of labels: {labels.size(0)}')\n","\n","    with gzip.open(images_path, 'rb') as imgpath:\n","        images = torch.from_numpy(np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).copy().reshape(-1, 784))\n","    print(f'Number of images: {images.size(0)}')\n","\n","    assert len(images) == len(labels)\n","\n","    return images, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:24.828121Z","iopub.status.busy":"2023-09-19T12:52:24.827656Z","iopub.status.idle":"2023-09-19T12:52:24.838257Z","shell.execute_reply":"2023-09-19T12:52:24.836659Z","shell.execute_reply.started":"2023-09-19T12:52:24.828089Z"},"trusted":true},"outputs":[],"source":["def load_mnist(path, kind='train'):\n","    \"\"\"Load MNIST data from `path`\"\"\"\n","    labels_path = os.path.join(path,'%s-labels-idx1-ubyte'\n","                               % kind)\n","    images_path = os.path.join(path,'%s-images-idx3-ubyte'\n","                               % kind)\n","    print(labels_path)\n","    print(images_path)\n","    with open(labels_path, 'rb') as lbpath:\n","        labels = torch.from_numpy(np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8).copy())\n","    print(f'Number of labels: {labels.size(0)}')\n","\n","    with open(images_path, 'rb') as imgpath:\n","        images = torch.from_numpy(np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).copy().reshape(-1, 784))\n","    print(f'Number of images: {images.size(0)}')\n","\n","    assert len(images) == len(labels)\n","\n","    return images, labels"]},{"cell_type":"markdown","metadata":{},"source":["## Some details about gzip, buffers & tensors\n","\n","The dataset provided is packed in a gzip file. So, I had to do some manipulation to do to return data in tensors to use in our model `train` & `valid` datasets. \n","\n","***Details/Notes***\n","\n","The numpy module is then used to convert the binary data into an array of unsigned 8-bit integers (np.uint8). The offset parameter is used to skip the first 8 bytes of the file, which contain metadata about the file format.\n","\n","Therefore, the labels variable is an array of unsigned 8-bit integers that represent the labels associated with a dataset. \n","\n","We apply `.reshape(-1, 784)`  to ensure that the number of images matches the number of labels.\n","Also, we `assert` so that it'll throw an AssertionError if the numbers doesn't match.\n","\n","About the warning `The given buffer is not writable, and PyTorch does not support non-writable tensors.`\n","This warning is raised because PyTorch is trying to create a tensor from a buffer that is not writable. This is not necessarily a problem, but it could potentially lead to unexpected behavior if you try to modify the tensor later on.\n","\n","To avoid this warning, we create a copy of the buffer before converting it to a tensor. \n"," \n","`.copy()` creates a copy of the numpy array. This is necessary because the original data is in a read-only buffer, but we need a writable copy to convert it to a PyTorch tensor.\n","\n","`torch.from_numpy()` converts the numpy array to a PyTorch tensor.\n","\n","### Creating the datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:28.012487Z","iopub.status.busy":"2023-09-19T12:52:28.011969Z","iopub.status.idle":"2023-09-19T12:52:28.663317Z","shell.execute_reply":"2023-09-19T12:52:28.661929Z","shell.execute_reply.started":"2023-09-19T12:52:28.012446Z"},"trusted":true},"outputs":[],"source":["# usage with the dataset from PyTorch as ubyte\n","trainImages, trainLabels = load_mnist(path=DATA_DIR, kind='train')\n","validImages, validLabels = load_mnist(path=DATA_DIR, kind='t10k')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:30.992328Z","iopub.status.busy":"2023-09-19T12:52:30.991847Z","iopub.status.idle":"2023-09-19T12:52:31.002432Z","shell.execute_reply":"2023-09-19T12:52:31.001172Z","shell.execute_reply.started":"2023-09-19T12:52:30.992293Z"},"trusted":true},"outputs":[],"source":["trainImages.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:31.880221Z","iopub.status.busy":"2023-09-19T12:52:31.879727Z","iopub.status.idle":"2023-09-19T12:52:31.888617Z","shell.execute_reply":"2023-09-19T12:52:31.887210Z","shell.execute_reply.started":"2023-09-19T12:52:31.880177Z"},"trusted":true},"outputs":[],"source":["trainLabels.shape"]},{"cell_type":"markdown","metadata":{},"source":["Images are uint8 (byte) while the neural network needs inputs as floating point in order to calculate gradients,\n","simply divide by 255 to get values into [0, 1]\n","Images are usually represented as arrays of integers, where each integer ranges from 0 to 255 to represent pixel intensity (0 being black and 255 being white, for grayscale images). However, when training a neural network, it's typically beneficial to feed in relatively small input values.\n","\n","By dividing by 255, you are performing a process called normalization, mapping pixel intensities from the range [0,255] to the range [0,1]."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:35.991749Z","iopub.status.busy":"2023-09-19T12:52:35.991252Z","iopub.status.idle":"2023-09-19T12:52:36.283327Z","shell.execute_reply":"2023-09-19T12:52:36.281740Z","shell.execute_reply.started":"2023-09-19T12:52:35.991706Z"},"trusted":true},"outputs":[],"source":["train_x = trainImages.view(-1, 1, 28, 28) # to reshape the tensor - as a rank from rank-3 to rank-2 \n","train_y = trainLabels.unsqueeze(1) # remove dimension 1\n","train_x = train_x.float()/255 \n","train_y = train_y.type(torch.LongTensor) # LongTensor is a signed 64-bit integer (long integer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:36.769023Z","iopub.status.busy":"2023-09-19T12:52:36.768399Z","iopub.status.idle":"2023-09-19T12:52:36.803334Z","shell.execute_reply":"2023-09-19T12:52:36.801776Z","shell.execute_reply.started":"2023-09-19T12:52:36.768981Z"},"trusted":true},"outputs":[],"source":["valid_x = validImages.view(-1, 1, 28, 28)\n","valid_y = validLabels.unsqueeze(1)\n","valid_x = valid_x.float()/255\n","valid_y = valid_y.type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T12:52:37.513324Z","iopub.status.busy":"2023-09-19T12:52:37.512840Z","iopub.status.idle":"2023-09-19T12:52:37.533680Z","shell.execute_reply":"2023-09-19T12:52:37.532027Z","shell.execute_reply.started":"2023-09-19T12:52:37.513282Z"},"trusted":true},"outputs":[],"source":["train_y.shape\n","valid_y[120].item()"]},{"cell_type":"markdown","metadata":{},"source":["**Notes**: About the reduction argument: in PyTorch loss functions is used to specify the reduction to apply to the output. It determines how the individual losses calculated across the mini-batch are combined into a single loss value.\n","\n","If you're implementing a custom loss function and you want it to be compatible with fastai's Learner and ClassificationInterpretation, you should make sure your function accepts a reduction argument and applies the specified reduction to the output.\n","\n","In most cases, you'll want to use 'mean', because it makes the training process more stable and the loss value easier to interpret. However, there might be cases where 'sum' is more appropriate, depending on your specific use case."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T14:19:47.477626Z","iopub.status.busy":"2023-09-19T14:19:47.477002Z","iopub.status.idle":"2023-09-19T14:19:47.486896Z","shell.execute_reply":"2023-09-19T14:19:47.485670Z","shell.execute_reply.started":"2023-09-19T14:19:47.477578Z"},"trusted":true},"outputs":[],"source":["def ce_loss(predictions, targets, reduction='mean'):\n","    targets = targets.squeeze()\n","    loss = F.cross_entropy(predictions, targets, reduction=reduction)\n","    return loss\n","\n","def batch_accuracy(xb, yb):\n","    preds = torch.argmax(xb, dim=1)  # Get the predicted classes , argmax, return indexes of .max() value for each tensor at dimension 1\n","    correct = (preds == yb.squeeze())  # Compare with targets , correct become a tensor of boolean value\n","    return correct.float().mean()  # Compute the mean accuracy, while correct.float()  boolean become float of value between 0 - 1. then mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T14:32:43.492902Z","iopub.status.busy":"2023-09-19T14:32:43.492377Z","iopub.status.idle":"2023-09-19T14:32:44.255835Z","shell.execute_reply":"2023-09-19T14:32:44.254354Z","shell.execute_reply.started":"2023-09-19T14:32:43.492862Z"},"trusted":true},"outputs":[],"source":["## CNN of 3 layers et 2D CONV of 32 feature detection layer + Dropouts & AdaptiveAvgPool2d \n","\n","learning_rate = 0.05754399299621582\n","train_dataset = list(zip(train_x,train_y))\n","valid_dataset = list(zip(valid_x,valid_y))\n","list_of_classes = validLabels.unique().tolist()\n","\n","conv_net = nn.Sequential(\n","    nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1), # Convolutional layer\n","    nn.ReLU(), # Activation function\n","    nn.Dropout(0.5), # Dropout for regularization\n","    nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=1), # Convolutional layer\n","    nn.ReLU(), # Activation function\n","    nn.Dropout(0.5), # Dropout for regularization\n","    nn.Conv2d(64, 10, kernel_size=5, stride=2, padding=1), # Convolutional layer\n","    nn.ReLU(), # Activation function\n","    nn.Dropout(0.5), # Dropout for regularization\n","    nn.AdaptiveAvgPool2d(1), # Adaptive average pooling\n","    Flatten(), # Flatten the tensor for the fully connected layer\n","    nn.Linear(10,10) # Fully connected layer\n",")\n","\n","train_dtl = DataLoader(train_dataset, batch_size=256)\n","valid_dtl = DataLoader(valid_dataset, batch_size=256)\n","dls = DataLoaders(train_dtl, valid_dtl)\n","dls.vocab = list_of_classes\n","learn = Learner(dls,conv_net,opt_func=Adam,lr=learning_rate, loss_func=ce_loss,metrics=batch_accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["I have improved the accuracy by changing the optimizer for Adam, and also changed the learn.fit() methid by using learn.fit_one_cycle() using momentums strategy.\n","\n","Notes: \n","- Learning rate slice param in fit_one_cycle() -> Rule of thumb for range: A common practice is to choose a range where the lower value is about 10 times smaller than the higher value. \n","- `moms` param stands for Default momentum for schedulers,  it's a tuple (mom1, mom2, mom3) that defines the two momentums used in the One Cycle Policy.\n","The One Cycle Policy is a learning rate schedule that involves training with increasing and then decreasing learning rates, and similarly, decreasing and then increasing momentums. \n","    - mom1: The initial momentum at the start of the cycle.\n","    - mom2: The momentum in the middle of the cycle.\n","    - mom3: The momentum at the end of the cycle.\n","    \n","    Typically, mom1 and mom3 are the same, representing a higher momentum value, and mom2 is a lower momentum value. This is based on the 1cycle policy which suggests using higher momentum at the start and end of the cycle, and lower momentum in the middle.This policy was proposed by Leslie Smith in his paper \"A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay\"."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T13:24:00.034271Z","iopub.status.busy":"2023-09-19T13:24:00.033728Z","iopub.status.idle":"2023-09-19T13:24:17.876378Z","shell.execute_reply":"2023-09-19T13:24:17.874920Z","shell.execute_reply.started":"2023-09-19T13:24:00.034205Z"},"trusted":true},"outputs":[],"source":["# below is the fastai function to help find an appropriate learning rate\n","learn.lr_find()\n","# we could use use learn.fit_one_cycle to ..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:00:54.933417Z","iopub.status.busy":"2023-09-19T15:00:54.932612Z","iopub.status.idle":"2023-09-19T15:14:52.360064Z","shell.execute_reply":"2023-09-19T15:14:52.358737Z","shell.execute_reply.started":"2023-09-19T15:00:54.933355Z"},"trusted":true},"outputs":[],"source":["learn.fit_one_cycle(20, slice(0.002511886414140463/10, 0.002511886414140463), moms=(0.95,0.85, 0.95))"]},{"cell_type":"markdown","metadata":{},"source":["## Model Interpretation\n","\n","Here we'll visualize few of our predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:14:56.123708Z","iopub.status.busy":"2023-09-19T15:14:56.123024Z","iopub.status.idle":"2023-09-19T15:14:57.994389Z","shell.execute_reply":"2023-09-19T15:14:57.993097Z","shell.execute_reply.started":"2023-09-19T15:14:56.123650Z"},"trusted":true},"outputs":[],"source":["# Get predictions and targets\n","preds, targs = learn.get_preds()\n","# Convert predictions to labels\n","pred_labels = [learn.dls.vocab[p.argmax()] for p in preds]\n","# Convert targets to labels\n","true_labels = [learn.dls.vocab[t] for t in targs]\n","# Now you can compare pred_labels and true_labels\n","for i in range(5):\n","    print(f'True label: {true_labels[i]} \\nPredicted label: {pred_labels[i]}\\n---')"]},{"cell_type":"markdown","metadata":{},"source":["Below we use per-class metrics with scikit-learn's classification report"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:18:21.679081Z","iopub.status.busy":"2023-09-19T15:18:21.678619Z","iopub.status.idle":"2023-09-19T15:18:21.731567Z","shell.execute_reply":"2023-09-19T15:18:21.730148Z","shell.execute_reply.started":"2023-09-19T15:18:21.679048Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# Convert target names to strings\n","target_names = [str(v) for v in learn.dls.vocab]\n","# Calculate per-class metrics\n","report = classification_report(true_labels, pred_labels, target_names=target_names)\n","\n","print(report)"]},{"cell_type":"markdown","metadata":{},"source":["### Manual(single) Inference use case on model directly\n","INPUT is our test file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:21.989421Z","iopub.status.busy":"2023-09-19T15:19:21.988906Z","iopub.status.idle":"2023-09-19T15:19:21.999808Z","shell.execute_reply":"2023-09-19T15:19:21.998538Z","shell.execute_reply.started":"2023-09-19T15:19:21.989380Z"},"trusted":true},"outputs":[],"source":["INPUT = valid_x[101]\n","img = transforms.transforms.ToPILImage()(INPUT) \n","img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:23.843016Z","iopub.status.busy":"2023-09-19T15:19:23.842384Z","iopub.status.idle":"2023-09-19T15:19:23.870670Z","shell.execute_reply":"2023-09-19T15:19:23.869353Z","shell.execute_reply.started":"2023-09-19T15:19:23.842971Z"},"trusted":true},"outputs":[],"source":["output = learn.model(INPUT.unsqueeze(0))\n","\n","# Get the class with the highest probability\n","_, predicted_class = torch.max(output, 1)\n","\n","print(predicted_class) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:25.073441Z","iopub.status.busy":"2023-09-19T15:19:25.072146Z","iopub.status.idle":"2023-09-19T15:19:25.080838Z","shell.execute_reply":"2023-09-19T15:19:25.079743Z","shell.execute_reply.started":"2023-09-19T15:19:25.073391Z"},"trusted":true},"outputs":[],"source":["# we can create a mapping of the tensor receive as output\n","class_names = ['zero', 'un', 'deux', 'trois', 'quatre', 'cinq', 'six', 'sept', 'huit', 'neuf']\n","predicted_class_name = class_names[predicted_class.item()]\n","\n","print(f\"The name of this number in french is:{predicted_class_name}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:38.936523Z","iopub.status.busy":"2023-09-19T15:19:38.936049Z","iopub.status.idle":"2023-09-19T15:19:38.954031Z","shell.execute_reply":"2023-09-19T15:19:38.952656Z","shell.execute_reply.started":"2023-09-19T15:19:38.936488Z"},"trusted":true},"outputs":[],"source":["learn.save('/kaggle/working/this-is-mnist-model-f1c')"]},{"cell_type":"markdown","metadata":{},"source":["### Export/save & inference\n","Due an issue I had with fastai export method and predict, I chose to export and do the inference with PyTorch (without the save() & predict() API methods from Fastai)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:45.358137Z","iopub.status.busy":"2023-09-19T15:19:45.357619Z","iopub.status.idle":"2023-09-19T15:19:45.369062Z","shell.execute_reply":"2023-09-19T15:19:45.367650Z","shell.execute_reply.started":"2023-09-19T15:19:45.358092Z"},"trusted":true},"outputs":[],"source":["# Save model state dictionary\n","torch.save(learn.model.state_dict(), Path()/'models/this-is-mnist-model-f1c.pth')\n","\n","# Load model state dictionary\n","model_state_dict = torch.load(Path()/'models/this-is-mnist-model-f1c.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:46.767018Z","iopub.status.busy":"2023-09-19T15:19:46.765615Z","iopub.status.idle":"2023-09-19T15:19:46.776396Z","shell.execute_reply":"2023-09-19T15:19:46.775164Z","shell.execute_reply.started":"2023-09-19T15:19:46.766940Z"},"trusted":true},"outputs":[],"source":["# Apply the state dictionary to your model\n","conv_net.load_state_dict(model_state_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:47.665467Z","iopub.status.busy":"2023-09-19T15:19:47.663940Z","iopub.status.idle":"2023-09-19T15:19:47.678459Z","shell.execute_reply":"2023-09-19T15:19:47.677144Z","shell.execute_reply.started":"2023-09-19T15:19:47.665411Z"},"trusted":true},"outputs":[],"source":["# Ensure the model is in evaluation mode\n","conv_net.eval()\n","\n","# Preprocess your input\n","input_data = INPUT\n","# Add an extra dimension for batch size\n","input_data = input_data.unsqueeze(0)\n","\n","# Make sure the input data is on the right device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","input_data = input_data.to(device)\n","\n","# Pass the input data to the model\n","with torch.no_grad():\n","    output = conv_net(input_data)\n","\n","# Postprocess the output\n","probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","n_predicted_class = probabilities.argmax().item()\n","\n","print(n_predicted_class)"]},{"cell_type":"markdown","metadata":{},"source":["### Mapping the result\n","We can create a mapping of the tensor receive as output and return the prediction as a different label. Below, we've mapped it to french word as value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:19:50.333286Z","iopub.status.busy":"2023-09-19T15:19:50.332832Z","iopub.status.idle":"2023-09-19T15:19:50.340560Z","shell.execute_reply":"2023-09-19T15:19:50.339315Z","shell.execute_reply.started":"2023-09-19T15:19:50.333252Z"},"trusted":true},"outputs":[],"source":["class_names = ['zero', 'un', 'deux', 'trois', 'quatre', 'cinq', 'six', 'sept', 'huit', 'neuf']\n","predicted_class_name = class_names[predicted_class.item()]\n","\n","print(predicted_class_name)"]},{"cell_type":"markdown","metadata":{},"source":["## Thanks! That's it! (for the basics)\n","In summary, in addition to the basics of machine learning engineering, I've learned how to use the Fastai API and integrate a custom model with it - a CNN in this case. I've also learned how to create a multi-class classification model, the basics of computer vision, and how to use PyTorch for saving a model and performing inference on it. Lastly, I've learned how to implement the model in a live project and create a demo as a Hugging Face space. You can view the demo on huggingface [here](https://huggingface.co/spaces/mgspl/mnist_basic).\n"," \n","Productive comments are welcome.\n","\n","Thanks for reading!"]},{"cell_type":"markdown","metadata":{},"source":["Oh. and for the demo app as a standalone python projet see below. \n","### More about `app.py`\n","\n","There was some conversion to opperate to create the same code for inference in a python file.\n","\n","***Manually map the state names from conv_net base model***\n","\n","In conv_net, which is a nn.Sequential model, the layers are automatically named with increasing integers starting from 0. However, in the ConvNet class, the layers are named according to the variable names you gave them (conv1, conv2, conv3, fc).\n","To resolve this issue, you can manually map the names from conv_net to the names in ConvNet."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:20:27.635651Z","iopub.status.busy":"2023-09-19T15:20:27.635126Z","iopub.status.idle":"2023-09-19T15:20:27.657392Z","shell.execute_reply":"2023-09-19T15:20:27.655575Z","shell.execute_reply.started":"2023-09-19T15:20:27.635608Z"},"trusted":true},"outputs":[],"source":["class Flatten(nn.Module):\n","    def forward(self, input):\n","        return input.view(input.size(0), -1)\n","\n","class NConvNet(nn.Module):\n","    def __init__(self):\n","        super(NConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(64, 10, kernel_size=5, stride=2, padding=1)\n","        self.fc = nn.Linear(10,10)\n","        self.dropout = nn.Dropout(0.5)\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        self.flatten = Flatten()\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.conv3(x))\n","        x = self.dropout(x)\n","        x = self.avgpool(x)\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        return x\n","\n","def n_predict(img, withGradio=False):\n","    if withGradio:\n","        img = Image.fromarray(img)\n","    \n","    transform = transforms.Compose([\n","        transforms.Resize((28, 28)),\n","        transforms.Grayscale(),\n","        transforms.ToTensor(),\n","    ])\n","\n","    img_tensor = transform(img)\n","    input_data = img_tensor\n","    input_data = input_data.unsqueeze(0)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Get the state_dict of conv_net\n","    state_dict = torch.load('/kaggle/working/models/this-is-mnist-model-f1c.pth') # adjust the path if needed\n","    \n","    # Define a new state_dict for ConvNet\n","    new_state_dict = OrderedDict()\n","\n","    # Manually map the state names from conv_net base model\n","    new_state_dict['conv1.weight'] = state_dict['0.weight']\n","    new_state_dict['conv1.bias'] = state_dict['0.bias']\n","    new_state_dict['conv2.weight'] = state_dict['3.weight']\n","    new_state_dict['conv2.bias'] = state_dict['3.bias']\n","    new_state_dict['conv3.weight'] = state_dict['6.weight']\n","    new_state_dict['conv3.bias'] = state_dict['6.bias']\n","    new_state_dict['fc.weight'] = state_dict['11.weight']\n","    new_state_dict['fc.bias'] = state_dict['11.bias']\n","\n","    # Load the new_state_dict into ConvNet\n","    model = NConvNet()\n","    model.load_state_dict(new_state_dict)\n","    \n","    model.to(device)\n","    model.eval()  # Set the model to evaluation mode\n","    \n","    # Pass the input data to the model\n","    with torch.no_grad():\n","        output = model(input_data)\n","\n","    # Postprocess the output\n","    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","    n_predicted_class = probabilities.argmax().item()\n","    return n_predicted_class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-19T15:20:29.546930Z","iopub.status.busy":"2023-09-19T15:20:29.546429Z","iopub.status.idle":"2023-09-19T15:20:29.563965Z","shell.execute_reply":"2023-09-19T15:20:29.562654Z","shell.execute_reply.started":"2023-09-19T15:20:29.546891Z"},"trusted":true},"outputs":[],"source":["n_predict(img)"]},{"cell_type":"markdown","metadata":{},"source":["Notebook on Kaggle: https://www.kaggle.com/code/mindgspl/exercise-mnist\n","Demo on Huggingface: https://huggingface.co/spaces/mgspl/mnist_basic"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
